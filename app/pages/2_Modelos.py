import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score
from PIL import Image


# -----------------------------
# T√çTULO
# -----------------------------
st.title("ü§ñ Comparaci√≥n de Modelos Predictivos ‚Äì Parkinson‚Äôs Telemonitoring")

st.markdown("""
Esta secci√≥n muestra la comparaci√≥n de varios modelos de Machine Learning aplicados para predecir **motor_UPDRS** 
a partir de las variables ac√∫sticas y cl√≠nicas del dataset.
""")

# -----------------------------
# CARGA DEL DATASET
# -----------------------------
@st.cache_data
def load_data():
    df = pd.read_csv("data/parkinsons_updrs.csv")
    df = df.rename(columns={'subject#': 'subject_id'})
    df = df.drop(['sex', 'subject_id', 'age'], axis=1, errors='ignore')
    return df

df = load_data()

# -----------------------------
# SEPARACI√ìN FEATURES / TARGET
# -----------------------------
X = df.drop(['motor_UPDRS', 'total_UPDRS'], axis=1)
y = df['motor_UPDRS']

# Escalado
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# -----------------------------
# DEFINICI√ìN DE MODELOS
# -----------------------------
models = {
    'Regresi√≥n Lineal': LinearRegression(),
    'Ridge Regression': Ridge(alpha=1.0),
    'Lasso Regression': Lasso(alpha=0.01),
    'Elastic Net': ElasticNet(alpha=0.1, l1_ratio=0.5),
    'Decision Tree': DecisionTreeRegressor(max_depth=5, random_state=42),
    'Random Forest': RandomForestRegressor(random_state=42),
    'Gradient Boosting': GradientBoostingRegressor(random_state=42),
    'SVR (RBF Kernel)': SVR(kernel='rbf')
}

results = {}

# -----------------------------
# ENTRENAMIENTO DE MODELOS
# -----------------------------
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    results[name] = {
        'MSE': mean_squared_error(y_test, y_pred),
        'R2': r2_score(y_test, y_pred),
        'y_pred': y_pred
    }

# -----------------------------
# M√âTRICAS ORDENADAS Y GR√ÅFICOS
# -----------------------------

# Convertir resultados a DataFrame
df_results = pd.DataFrame(results).T

# Normalizar columna R2 ‚Üí R¬≤
df_results = df_results.rename(columns={"R2": "R¬≤"})

# Ordenar de mejor a peor rendimiento
df_results_sorted = df_results.sort_values(by="R¬≤", ascending=False)

# Mostrar tabla ordenada
st.subheader("üìä M√©tricas de rendimiento de cada modelo (ordenadas por R¬≤)")
st.dataframe(df_results_sorted[['MSE', 'R¬≤']])

# -----------------------------
# GRAFICO COMPARATIVO DE M√âTRICAS
# -----------------------------
st.subheader("üìà Comparaci√≥n gr√°fica de rendimiento (MSE y R¬≤)")

# Preparar rankings
df_r2 = df_results_sorted.reset_index().rename(columns={"index": "Modelo"})
df_mse = df_results.sort_values(by="MSE", ascending=True).reset_index().rename(columns={"index": "Modelo"})

# Crear la figura
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# --- Gr√°fico R¬≤ (de mejor a peor) ---
sns.barplot(
    x="Modelo", 
    y="R¬≤", 
    data=df_r2,
    palette="crest",
    ax=axes[0]
)
axes[0].set_title("Ranking de Modelos por R¬≤ (mejor ‚Üí peor)")
axes[0].set_ylabel("R¬≤")
axes[0].set_xlabel("Modelo")
axes[0].tick_params(axis='x', rotation=45)

# --- Gr√°fico MSE (de mejor a peor) ---
sns.barplot(
    x="Modelo", 
    y="MSE", 
    data=df_mse,
    palette="flare",
    ax=axes[1]
)
axes[1].set_title("Ranking de Modelos por MSE (menor error ‚Üí mayor error)")
axes[1].set_ylabel("MSE")
axes[1].set_xlabel("Modelo")
axes[1].tick_params(axis='x', rotation=45)

plt.suptitle("Comparaci√≥n ordenada de rendimiento entre modelos", fontsize=15, y=1.05)
plt.tight_layout()
plt.show()
st.pyplot(fig)

st.subheader("üìù Conclusiones")

st.markdown("""
Random Forest fue elegido como modelo final porque obtuvo el mejor R¬≤ y el menor MSE, superando al resto de modelos. Esto indica que captura mejor las relaciones no lineales y la complejidad del dataset, mientras que los modelos lineales no lograron adaptarse tan bien.
""")
# -----------------------------
# IMPORTANCIA DE VARIABLES (RANDOM FOREST)
# -----------------------------
st.subheader("üåü Importancia de variables (Random Forest)")

rf = RandomForestRegressor(random_state=42)
rf.fit(X, y)
importances = rf.feature_importances_

feat_importances = pd.DataFrame({
    'Variable': X.columns,
    'Importancia': importances
}).sort_values(by='Importancia', ascending=False)

fig, ax = plt.subplots(figsize=(6, 6))
sns.barplot(data=feat_importances, x='Importancia', y='Variable', palette='crest')
plt.title("Importancia de Variables")
st.pyplot(fig)


st.subheader("üîÅ Permutation Importance")

# Mostrar imagen de forma responsiva
try:
    image = Image.open("app/images/permutation_importance.png")

    # Layout responsivo para m√≥viles
    col1, col2, col3 = st.columns([1, 3, 1])
    with col2:
        st.image(image, caption="Permutation Importance ‚Äì Random Forest", use_column_width=True)

except:
    st.warning("‚ö†Ô∏è No se pudo cargar la imagen. Aseg√∫rate de generar la imagen en el notebook.")

# -----------------------------
# TEXTO AUTOM√ÅTICO: Interpretaci√≥n de las 3 variables m√°s importantes
# -----------------------------
st.subheader("üìò Interpretaci√≥n autom√°tica de las 3 variables m√°s importantes")

# Diccionario de descripciones cl√≠nicas
descripcion_variables = {
    "test_time": "Momento dentro del seguimiento. Indica progresi√≥n temporal de la enfermedad.",
    "Jitter(%)": "Variaci√≥n r√°pida de frecuencia. Se relaciona con inestabilidad vocal por alteraciones motoras.",
    "Jitter(Abs)": "Cambios absolutos en frecuencia. Refleja vibraci√≥n irregular de las cuerdas vocales.",
    "Jitter:RAP": "Promedio de variaciones sucesivas ‚Äî asociado al temblor fino vocal.",
    "Jitter:PPQ5": "Variaci√≥n de frecuencia a corto plazo, relacionada con p√©rdida de control muscular.",
    "Jitter:DDP": "Derivado de RAP ‚Äî mide inestabilidad de vibraci√≥n.",
    "Shimmer": "Variaci√≥n de amplitud ‚Äî evidencia rigidez y fatiga muscular.",
    "Shimmer(dB)": "Oscilaci√≥n de amplitud en decibelios ‚Äî fuerte indicador de deterioro vocal.",
    "Shimmer:APQ3": "Promedio de diferencias de amplitud ‚Äî estabilidad fonatoria.",
    "Shimmer:APQ5": "Variabilidad de amplitud a corto plazo.",
    "Shimmer:APQ11": "Variaci√≥n a largo plazo ‚Äî voz m√°s irregular.",
    "Shimmer:DDA": "Derivado de APQ3 ‚Äî irregularidad muscular.",
    "NHR": "Relaci√≥n ruido-armon√≠a. A mayor ruido, peor calidad vocal.",
    "HNR": "Relaci√≥n arm√≥nico-ruido. Valores bajos muestran voz deteriorada.",
    "RPDE": "Medida de complejidad temporal de la se√±al vocal.",
    "DFA": "Captura la din√°mica no lineal del habla.",
    "PPE": "Indicador de irregularidad del tono."
}

# Cargar el dataframe usado para generar las importancias
# (Debe coincidir con el orden de la imagen)
try:
    import pandas as pd
    feat_perm = pd.read_csv("app/images/feat_perm_values.csv")  # OPCIONAL si guardaste los datos

    top3 = feat_perm.head(3)

    st.markdown("### ü•á Variables m√°s influyentes en el modelo")

    for i, row in top3.iterrows():
        var = row["Variable"]
        imp = row["Importancia"]

        st.markdown(f"""
        **üîπ {var}**  
        Importancia: `{imp:.4f}`  
        **Interpretaci√≥n:** {descripcion_variables.get(var, "No hay interpretaci√≥n disponible.")}  
        """)

except:
    st.info("""
    ‚ÑπÔ∏è Para generar el texto autom√°tico, puedes guardar el dataframe de Permutation Importance
    como `feat_perm_values.csv` desde el notebook.
    """)