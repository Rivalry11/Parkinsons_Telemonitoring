import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score


# -----------------------------
# T√çTULO
# -----------------------------
st.title("ü§ñ Comparaci√≥n de Modelos Predictivos ‚Äì Parkinson‚Äôs Telemonitoring")

st.markdown("""
Esta secci√≥n muestra la comparaci√≥n de varios modelos de Machine Learning aplicados para predecir **motor_UPDRS** 
a partir de las variables ac√∫sticas y cl√≠nicas del dataset.
""")

# -----------------------------
# CARGA DEL DATASET
# -----------------------------
@st.cache_data
def load_data():
    df = pd.read_csv("data/parkinsons_updrs.csv")
    df = df.rename(columns={'subject#': 'subject_id'})
    df = df.drop(['sex', 'subject_id', 'age'], axis=1, errors='ignore')
    return df

df = load_data()

# -----------------------------
# SEPARACI√ìN FEATURES / TARGET
# -----------------------------
X = df.drop(['motor_UPDRS', 'total_UPDRS'], axis=1)
y = df['motor_UPDRS']

# Escalado
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# -----------------------------
# DEFINICI√ìN DE MODELOS
# -----------------------------
models = {
    'Regresi√≥n Lineal': LinearRegression(),
    'Ridge Regression': Ridge(alpha=1.0),
    'Lasso Regression': Lasso(alpha=0.01),
    'Elastic Net': ElasticNet(alpha=0.1, l1_ratio=0.5),
    'Decision Tree': DecisionTreeRegressor(max_depth=5, random_state=42),
    'Random Forest': RandomForestRegressor(random_state=42),
    'Gradient Boosting': GradientBoostingRegressor(random_state=42),
    'SVR (RBF Kernel)': SVR(kernel='rbf')
}

results = {}

# -----------------------------
# ENTRENAMIENTO DE MODELOS
# -----------------------------
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    results[name] = {
        'MSE': mean_squared_error(y_test, y_pred),
        'R2': r2_score(y_test, y_pred),
        'y_pred': y_pred
    }

# -----------------------------
# M√âTRICAS ORDENADAS Y GR√ÅFICOS
# -----------------------------

# Convertir resultados a DataFrame
df_results = pd.DataFrame(results).T

# Normalizar columna R2 ‚Üí R¬≤
df_results = df_results.rename(columns={"R2": "R¬≤"})

# Ordenar de mejor a peor rendimiento
df_results_sorted = df_results.sort_values(by="R¬≤", ascending=False)

# Mostrar tabla ordenada
st.subheader("üìä M√©tricas de rendimiento de cada modelo (ordenadas por R¬≤)")
st.dataframe(df_results_sorted[['MSE', 'R¬≤']])

# -----------------------------
# GRAFICO COMPARATIVO DE M√âTRICAS
# -----------------------------
st.subheader("üìà Comparaci√≥n gr√°fica de rendimiento (MSE y R¬≤)")

# Preparar rankings
df_r2 = df_results_sorted.reset_index().rename(columns={"index": "Modelo"})
df_mse = df_results.sort_values(by="MSE", ascending=True).reset_index().rename(columns={"index": "Modelo"})

# Crear la figura
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# --- Gr√°fico R¬≤ (de mejor a peor) ---
sns.barplot(
    x="Modelo", 
    y="R¬≤", 
    data=df_r2,
    palette="crest",
    ax=axes[0]
)
axes[0].set_title("Ranking de Modelos por R¬≤ (mejor ‚Üí peor)")
axes[0].set_ylabel("R¬≤")
axes[0].set_xlabel("Modelo")
axes[0].tick_params(axis='x', rotation=45)

# --- Gr√°fico MSE (de mejor a peor) ---
sns.barplot(
    x="Modelo", 
    y="MSE", 
    data=df_mse,
    palette="flare",
    ax=axes[1]
)
axes[1].set_title("Ranking de Modelos por MSE (menor error ‚Üí mayor error)")
axes[1].set_ylabel("MSE")
axes[1].set_xlabel("Modelo")
axes[1].tick_params(axis='x', rotation=45)

plt.suptitle("Comparaci√≥n ordenada de rendimiento entre modelos", fontsize=15, y=1.05)
plt.tight_layout()
plt.show()
st.pyplot(fig)

# -----------------------------
# IMPORTANCIA DE VARIABLES (RANDOM FOREST)
# -----------------------------
st.subheader("üåü Importancia de variables (Random Forest)")

rf = RandomForestRegressor(random_state=42)
rf.fit(X, y)
importances = rf.feature_importances_

feat_importances = pd.DataFrame({
    'Variable': X.columns,
    'Importancia': importances
}).sort_values(by='Importancia', ascending=False)

fig, ax = plt.subplots(figsize=(6, 6))
sns.barplot(data=feat_importances, x='Importancia', y='Variable', palette='crest')
plt.title("Importancia de Variables")
st.pyplot(fig)
# -----------------------------
# PERMUTATION IMPORTANCE ‚Äî SOLO SI EL USUARIO LO SOLICITA
# -----------------------------
st.subheader("üîÅ Permutation Importance (c√°lculo m√°s lento)")

if st.button("Calcular Permutation Importance"):
    with st.spinner("Calculando... puede tardar unos segundos"):
        from sklearn.inspection import permutation_importance
        result = permutation_importance(
            rf, X_test, y_test,
            n_repeats=10,
            random_state=42,
            n_jobs=-1
        )

        feat_perm = pd.DataFrame({
            "Variable": X.columns,
            "Importancia": result.importances_mean,
            "STD": result.importances_std
        }).sort_values(by="Importancia", ascending=False)

        # Gr√°fico
        fig2, ax2 = plt.subplots(figsize=(8, 6))
        sns.barplot(data=feat_perm, x="Importancia", y="Variable", palette="viridis")
        plt.title("Permutation Importance ‚Äì Random Forest")
        st.pyplot(fig2)

        # Tabla explicativa
        st.subheader("üìò Interpretaci√≥n de las variables m√°s importantes")
        explicacion = {
            "test_time": "Indica progresi√≥n temporal del paciente.",
            "Jitter(%)": "Variaci√≥n de frecuencia ‚Äî refleja inestabilidad vocal.",
            "Jitter(Abs)": "Cambio absoluto en frecuencia ‚Äî vibraci√≥n irregular.",
            "Jitter:RAP": "Variaci√≥n r√°pida ‚Äî temblor fino.",
            "Jitter:PPQ5": "Variaci√≥n a corto plazo.",
            "Jitter:DDP": "Medida derivada de RAP.",
            "Shimmer": "Variaci√≥n en amplitud ‚Äî rigidez muscular.",
            "Shimmer(dB)": "Oscilaci√≥n dB ‚Äî severidad vocal.",
            "Shimmer:APQ3": "Amplitud promediada ‚Äî estabilidad de fonaci√≥n.",
            "Shimmer:APQ5": "Variabilidad de amplitud.",
            "Shimmer:APQ11": "Variabilidad de amplitud a largo plazo.",
            "Shimmer:DDA": "Variaci√≥n derivada de APQ3.",
            "NHR": "Ruido presente en la se√±al vocal.",
            "HNR": "Relaci√≥n arm√≥nico-ruido.",
            "RPDE": "Complejidad temporal de la se√±al.",
            "DFA": "Dinamismo no lineal de la voz.",
            "PPE": "Estimaci√≥n de probabilidad de error en tono."
        }

        info_df = pd.DataFrame({
            "Variable": feat_perm["Variable"],
            "Importancia": feat_perm["Importancia"].round(4),
            "Interpretaci√≥n": feat_perm["Variable"].map(explicacion)
        })

        st.dataframe(info_df)